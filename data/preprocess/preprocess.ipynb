{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xml格式转换为Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_xml_string(file_path): \n",
    "    with open(file_path, 'r') as f:\n",
    "        doc_string = f.read()\n",
    "        \n",
    "    soup = BS(doc_string)\n",
    "    sentence_elements = soup.find_all('sentence')\n",
    "    \n",
    "    sentences = []\n",
    "    for i, elem in enumerate(sentence_elements):\n",
    "        elem = str(elem)\n",
    "        elem = elem.replace('\\n', '').replace('\\t', '').replace('\\r', '')\n",
    "        \n",
    "        pattern = re.compile('>[\\u4e00-\\u9fa50-9A-Za-z.，。！？：；“”\"（）《》]+<')\n",
    "        sentence = ' '.join([x.replace('<', '').replace('>', '') for x in pattern.findall(elem)])\n",
    "        \n",
    "        sentences.append(sentence)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_xml(file_path, save_dir):\n",
    "    json_sentences = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        doc_string = f.read()\n",
    "    doc = xmltodict.parse(doc_string)\n",
    "    paragraphs = doc['Body']['Content']['Paragraph']\n",
    "\n",
    "    if type(paragraphs) != list:\n",
    "        assert type(paragraphs) == collections.OrderedDict\n",
    "        paragraphs = [paragraphs]\n",
    "\n",
    "    for i, paragraph in enumerate(paragraphs):\n",
    "        try:\n",
    "            sentences = paragraph['Sentence']\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if type(sentences) != list:\n",
    "            sentences = [sentences]\n",
    "\n",
    "        for j, sentence in enumerate(sentences):\n",
    "            json_sentence = collections.OrderedDict()\n",
    "            \n",
    "            try:\n",
    "                events = sentence['Event']\n",
    "            except:\n",
    "                assert type(sentence) == str\n",
    "                json_sentences.append(json_sentence)\n",
    "                continue\n",
    "\n",
    "            if type(events) != list:\n",
    "                assert type(events) == collections.OrderedDict\n",
    "                events = [events]\n",
    "            \n",
    "            for e, event in enumerate(events):\n",
    "                json_event = collections.OrderedDict()\n",
    "                \n",
    "                for k, v in event.items():\n",
    "                    if k in ['@eid', '#text']:\n",
    "                        continue\n",
    "                        \n",
    "                    if type(v) == collections.OrderedDict:\n",
    "                        if k == 'Denoter':\n",
    "                            json_event[k] = v\n",
    "                        else:\n",
    "                            try:\n",
    "                                json_event[k] = v['#text']\n",
    "                            except:\n",
    "                                continue\n",
    "                                \n",
    "                    else:\n",
    "                        json_event[k] = v\n",
    "                \n",
    "                json_sentence['event{}'.format(e)] = json_event\n",
    "                \n",
    "            json_sentences.append(json_sentence)\n",
    "    \n",
    "    \n",
    "    raw_sentences = parse_xml_string(file_path)\n",
    "    try:\n",
    "        assert len(raw_sentences) == len(json_sentences)\n",
    "    except:\n",
    "        assert file_path == './CEC/食物中毒/印度发生假酒集体中毒事件.xml'\n",
    "        del raw_sentences[3]\n",
    "        assert len(raw_sentences) == len(json_sentences)\n",
    "    \n",
    "    for i, json_sentence in enumerate(json_sentences):\n",
    "        json_sentence['sentence'] = raw_sentences[i]\n",
    "    \n",
    "    file_name = file_path.split('/')[-1].split('.xml')[0]\n",
    "    with open('{}/{}.json'.format(save_dir, file_name), 'w') as f:\n",
    "        json.dump(json_sentences, f, indent=4, ensure_ascii=False, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_files = []\n",
    "for path, dir_list, file_list in os.walk('./CEC/'):\n",
    "    for file_name in file_list:\n",
    "        if '.xml' in file_name:\n",
    "            xml_files.append(os.path.join(path, file_name))\n",
    "len(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for xml_file in xml_files:\n",
    "    parse_xml(xml_file, save_dir='./CEC-xml2json/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 筛选可用句子，构造 Event Extraction 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import jieba\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2207"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_files = []\n",
    "for path, dir_list, file_list in os.walk('./CEC-xml2json/'):\n",
    "    for file_name in file_list:\n",
    "        if '.json' in file_name:\n",
    "            json_files.append(os.path.join(path, file_name))\n",
    "len(json_files)\n",
    "\n",
    "sentences = []\n",
    "for json_file in json_files:\n",
    "    with open(json_file, 'r') as f:\n",
    "        sentences += json.load(f)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event0': {'Denoter': {'#text': '火灾', '@did': 'd1', '@type': 'emergency'},\n",
       "  'Location': '广州番禺市桥街兴泰路',\n",
       "  'Object': '商铺',\n",
       "  'Time': '2014年1月7日'},\n",
       " 'event1': {'Denoter': {'#text': '烧死', '@did': 'd2', '@type': 'emergency'},\n",
       "  'Participant': '从化女子'},\n",
       " 'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_sentence(text):\n",
    "    cut_text = ''\n",
    "\n",
    "    texts = text.split()\n",
    "    for t in texts:\n",
    "        cut_text += ' '.join(list(jieba.cut(t))) + ' '\n",
    "\n",
    "    return cut_text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/kz/g2361vfn397dqyxgt9n8bk6r0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "广州番禺警方 媒体 通报 ： 1月7日晚21时40分 警方 群众 报警 ， 称 市桥街兴泰路 商铺 冒出 浓烟 。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.190 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'广州 番禺 警方 媒体 通报 ： 1 月 7 日晚 21 时 40 分 警方 群众 报警 ， 称 市桥 街兴泰路 商铺 冒 出 浓烟 。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentences[2]['sentence'])\n",
    "cut_sentence(sentences[2]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    # 没有event字段\n",
    "    if len(sentence) == 1:\n",
    "        continue\n",
    "    \n",
    "    valid_sentence = dict()\n",
    "    \n",
    "    text = sentence['sentence']\n",
    "    cut_text = cut_sentence(text)\n",
    "    words = cut_text.split()\n",
    "    valid_sentence['sentence'] = text\n",
    "    valid_sentence['sentence_words'] = cut_text\n",
    "    \n",
    "    triggers = []\n",
    "    for key, value in sentence.items():\n",
    "        if 'event' not in key:\n",
    "            continue\n",
    "            \n",
    "        trigger = dict()\n",
    "        \n",
    "        # event trigger: Denoter 字段\n",
    "        try:\n",
    "            trigger['event'] = value['Denoter']['@type']\n",
    "            # 去掉 thoughtevent 的事件\n",
    "            if trigger['event'] == 'thoughtevent':\n",
    "                continue\n",
    "            trigger['event_trigger'] = value['Denoter']['#text']\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        ## check trigger word ##\n",
    "        if trigger['event_trigger'] not in words:\n",
    "            continue\n",
    "\n",
    "        # event arguments: Participant/Object 字段\n",
    "        if 'Participant' in value.keys():\n",
    "            participants = value['Participant']\n",
    "\n",
    "            if type(participants) == list:\n",
    "                ## check arguments word ##\n",
    "                for participant in participants:\n",
    "                    if participant not in words:\n",
    "                        continue\n",
    "                    \n",
    "                    if 'event_arguments' not in trigger.keys():\n",
    "                        trigger['event_arguments'] = [participant]\n",
    "                    else:\n",
    "                        trigger['event_arguments'].append(participant)\n",
    "            else:\n",
    "                assert type(participants) == str\n",
    "                \n",
    "                ## check arguments word ##\n",
    "                if participants not in words:\n",
    "                    continue\n",
    "                    \n",
    "                trigger['event_arguments'] = [participants]\n",
    "\n",
    "        elif 'Object' in value.keys():\n",
    "            participants = value['Object']\n",
    "            \n",
    "            ## check arguments word ##\n",
    "            if participants not in words:\n",
    "                continue\n",
    "                    \n",
    "            trigger['event_arguments'] = [participants]\n",
    "            \n",
    "\n",
    "        triggers.append(trigger)\n",
    "    \n",
    "    if len(triggers) == 0:\n",
    "        continue\n",
    "        \n",
    "    valid_sentence['triggers'] = triggers\n",
    "    valid_sentences.append(valid_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2207, 1665)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(valid_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！',\n",
       " 'sentence_words': '2014 年 1 月 7 日 广州 番禺市 桥街 兴泰路 商铺 火灾 ， 从化 女子 烧死 ！',\n",
       " 'triggers': [{'event': 'emergency',\n",
       "   'event_arguments': ['商铺'],\n",
       "   'event_trigger': '火灾'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./dataset.json', 'w') as f:\n",
    "    json.dump(valid_sentences, f, sort_keys=True, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./dataset.json', 'r') as f:\n",
    "    sentences = json.load(f)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！',\n",
       " 'sentence_words': '2014 年 1 月 7 日 广州 番禺市 桥街 兴泰路 商铺 火灾 ， 从化 女子 烧死 ！',\n",
       " 'triggers': [{'event': 'emergency',\n",
       "   'event_arguments': '商铺',\n",
       "   'event_trigger': '火灾',\n",
       "   'index_event': 1,\n",
       "   'index_event_arguments': 10,\n",
       "   'index_event_trigger': 11}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '广州番禺警方 媒体 通报 ： 1月7日晚21时40分 警方 群众 报警 ， 称 市桥街兴泰路 商铺 冒出 浓烟 。',\n",
       " 'sentence_words': '广州 番禺 警方 媒体 通报 ： 1 月 7 日晚 21 时 40 分 警方 群众 报警 ， 称 市桥 街兴泰路 商铺 冒 出 浓烟 。',\n",
       " 'triggers': [{'event': 'statement',\n",
       "   'event_trigger': '称',\n",
       "   'index_event': 6,\n",
       "   'index_event_trigger': 18},\n",
       "  {'event': 'statement',\n",
       "   'event_trigger': '通报',\n",
       "   'index_event': 6,\n",
       "   'index_event_trigger': 4},\n",
       "  {'event': 'operation',\n",
       "   'event_trigger': '报警',\n",
       "   'index_event': 3,\n",
       "   'index_event_trigger': 16}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句子中 Event Trigger 数量统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！',\n",
       " 'sentence_words': '2014 年 1 月 7 日 广州 番禺市 桥街 兴泰路 商铺 火灾 ， 从化 女子 烧死 ！',\n",
       " 'triggers': [{'event': 'emergency',\n",
       "   'event_arguments': ['商铺'],\n",
       "   'event_trigger': '火灾'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triggers_num = [len(s['triggers']) for s in sentences]\n",
    "len(triggers_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triggers_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1665.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.045646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.298235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       triggers_num\n",
       "count   1665.000000\n",
       "mean       2.045646\n",
       "std        1.298235\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        2.000000\n",
       "75%        3.000000\n",
       "max        8.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triggers_df = pd.DataFrame({'triggers_num': triggers_num})\n",
    "triggers_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/1 比例（句子中只有一个事件）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triggers_df[triggers_df['triggers_num'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4594594594594595"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triggers_df[triggers_df['triggers_num'] == 1]) / len(triggers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/N 比例 （句子中有多个事件）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triggers_df[triggers_df['triggers_num'] > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5405405405405406"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triggers_df[triggers_df['triggers_num'] > 1]) / len(triggers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '近日 ，八通网百姓热线，被撞男孩 父亲 发帖 描述 事发经过 ， 据 他 称 ， 11月14日早上6点40分左右 ， 13岁的儿子 骑 到 玉桥中学 上学 ， 行至 时 ， 被 一辆车牌号为京EY122的通州城管执法车（白色现代索纳塔） 撞伤 ， 儿子 被 拖行 了40余米 ， 幸亏 路人 和 玉桥中学的老师 相 救 ， 及时 送 到 潞河医院 抢救 。',\n",
       " 'sentence_words': '近日 ， 八通网 百姓 热线 ， 被 撞 男孩 父亲 发帖 描述 事发 经过 ， 据 他 称 ， 11 月 14 日 早上 6 点 40 分 左右 ， 13 岁 的 儿子 骑 到 玉桥 中学 上学 ， 行至 时 ， 被 一辆 车牌号 为京 EY122 的 通州 城管 执法 车 （ 白色 现代 索纳塔 ） 撞伤 ， 儿子 被 拖行 了 40 余米 ， 幸亏 路 人 和 玉桥 中学 的 老师 相 救 ， 及时 送 到 潞河 医院 抢救 。',\n",
       " 'triggers': [{'event': 'action', 'event_trigger': '上学'},\n",
       "  {'event': 'statement', 'event_arguments': ['父亲'], 'event_trigger': '描述'},\n",
       "  {'event': 'action', 'event_trigger': '救'},\n",
       "  {'event': 'action', 'event_trigger': '送'},\n",
       "  {'event': 'movement', 'event_trigger': '行至'},\n",
       "  {'event': 'action', 'event_trigger': '抢救'},\n",
       "  {'event': 'statement', 'event_arguments': ['他'], 'event_trigger': '称'},\n",
       "  {'event': 'movement', 'event_arguments': ['儿子'], 'event_trigger': '拖行'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[triggers_num.index(8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event 类型统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_type = dict()\n",
    "\n",
    "for sent in sentences:\n",
    "    for trigger in sent['triggers']:\n",
    "        t = trigger['event']\n",
    "        if t not in event_type.keys():\n",
    "            event_type[t] = 1\n",
    "        else:\n",
    "            event_type[t] += 1\n",
    "\n",
    "len(event_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 639,\n",
       " 'emergency': 599,\n",
       " 'movement': 302,\n",
       " 'operation': 764,\n",
       " 'perception': 202,\n",
       " 'stateChange': 415,\n",
       " 'statement': 485}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Argument 数量统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！',\n",
       " 'sentence_words': '2014 年 1 月 7 日 广州 番禺市 桥街 兴泰路 商铺 火灾 ， 从化 女子 烧死 ！',\n",
       " 'triggers': [{'event': 'emergency',\n",
       "   'event_arguments': ['商铺'],\n",
       "   'event_trigger': '火灾'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3406"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments_num = []\n",
    "\n",
    "for sent in sentences:\n",
    "    for trigger in sent['triggers']:\n",
    "        if 'event_arguments' not in trigger.keys():\n",
    "            arguments_num.append(0)\n",
    "        else:\n",
    "            arguments_num.append(len(trigger['event_arguments']))\n",
    "\n",
    "len(arguments_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.449501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               num\n",
       "count  3406.000000\n",
       "mean      0.449501\n",
       "std       0.497516\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments_df = pd.DataFrame({'num': arguments_num})\n",
    "arguments_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1875\n",
       "1    1531\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments_df['num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.550499\n",
       "1    0.449501\n",
       "Name: num, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments_df['num'].value_counts() / len(arguments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把 event arguments 的类型，由list -> str\n",
    "for sent in sentences:\n",
    "    for trigger in sent['triggers']:\n",
    "        if 'event_arguments' in trigger.keys():\n",
    "            trigger['event_arguments'] = trigger['event_arguments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！',\n",
       " 'sentence_words': '2014 年 1 月 7 日 广州 番禺市 桥街 兴泰路 商铺 火灾 ， 从化 女子 烧死 ！',\n",
       " 'triggers': [{'event': 'emergency',\n",
       "   'event_arguments': '商铺',\n",
       "   'event_trigger': '火灾'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./dataset.json', 'w') as f:\n",
    "    json.dump(sentences, f, sort_keys=True, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 最大句子长度：85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！',\n",
       " 'sentence_words': '2014 年 1 月 7 日 广州 番禺市 桥街 兴泰路 商铺 火灾 ， 从化 女子 烧死 ！',\n",
       " 'triggers': [{'event': 'emergency',\n",
       "   'event_arguments': '商铺',\n",
       "   'event_trigger': '火灾'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = []\n",
    "for piece in sentences:\n",
    "    nums.append(len(piece['sentence_words'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 120)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nums), nums.index(max(nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '近日 ，八通网百姓热线，被撞男孩 父亲 发帖 描述 事发经过 ， 据 他 称 ， 11月14日早上6点40分左右 ， 13岁的儿子 骑 到 玉桥中学 上学 ， 行至 时 ， 被 一辆车牌号为京EY122的通州城管执法车（白色现代索纳塔） 撞伤 ， 儿子 被 拖行 了40余米 ， 幸亏 路人 和 玉桥中学的老师 相 救 ， 及时 送 到 潞河医院 抢救 。',\n",
       " 'sentence_words': '近日 ， 八通网 百姓 热线 ， 被 撞 男孩 父亲 发帖 描述 事发 经过 ， 据 他 称 ， 11 月 14 日 早上 6 点 40 分 左右 ， 13 岁 的 儿子 骑 到 玉桥 中学 上学 ， 行至 时 ， 被 一辆 车牌号 为京 EY122 的 通州 城管 执法 车 （ 白色 现代 索纳塔 ） 撞伤 ， 儿子 被 拖行 了 40 余米 ， 幸亏 路 人 和 玉桥 中学 的 老师 相 救 ， 及时 送 到 潞河 医院 抢救 。',\n",
       " 'triggers': [{'event': 'action', 'event_trigger': '上学'},\n",
       "  {'event': 'statement', 'event_arguments': '父亲', 'event_trigger': '描述'},\n",
       "  {'event': 'action', 'event_trigger': '救'},\n",
       "  {'event': 'action', 'event_trigger': '送'},\n",
       "  {'event': 'movement', 'event_trigger': '行至'},\n",
       "  {'event': 'action', 'event_trigger': '抢救'},\n",
       "  {'event': 'statement', 'event_arguments': '他', 'event_trigger': '称'},\n",
       "  {'event': 'movement', 'event_arguments': '儿子', 'event_trigger': '拖行'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train/Test 划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照event trigger的数量来分层抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./dataset.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '2014年1月7日 广州番禺市桥街兴泰路 商铺 火灾 ， 从化女子 烧死 ！',\n",
       " 'sentence_words': '2014 年 1 月 7 日 广州 番禺市 桥街 兴泰路 商铺 火灾 ， 从化 女子 烧死 ！',\n",
       " 'triggers': [{'event': 'emergency',\n",
       "   'event_arguments': '商铺',\n",
       "   'event_trigger': '火灾',\n",
       "   'index_event': 1,\n",
       "   'index_event_arguments': 10,\n",
       "   'index_event_trigger': 11}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triggers_num = [len(p['triggers']) for p in dataset]\n",
    "len(triggers_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 3, 1, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triggers_num[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(triggers_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1665,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(len(dataset))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1332,), (333,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index, test_index = train_test_split(y, test_size=0.2, stratify=triggers_num, random_state=0)\n",
    "train_index.shape, test_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_triggers_num(indexes):\n",
    "    num = np.array(triggers_num)\n",
    "    \n",
    "    chosen_num = num[indexes]\n",
    "    events = list(set(chosen_num))\n",
    "    events.sort()\n",
    "    \n",
    "    num2len = dict()\n",
    "    for e in events:\n",
    "        num2len[e] = len(chosen_num[chosen_num==e])\n",
    "    \n",
    "    print(num2len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 765, 2: 429, 3: 249, 4: 131, 5: 55, 6: 20, 7: 11, 8: 5}\n"
     ]
    }
   ],
   "source": [
    "check_triggers_num(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 612, 2: 343, 3: 199, 4: 105, 5: 44, 6: 16, 7: 9, 8: 4}\n"
     ]
    }
   ],
   "source": [
    "check_triggers_num(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 153, 2: 86, 3: 50, 4: 26, 5: 11, 6: 4, 7: 2, 8: 1}\n"
     ]
    }
   ],
   "source": [
    "check_triggers_num(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
